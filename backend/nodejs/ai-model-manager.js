/**
 * QMS-AI é…ç½®é©±åŠ¨çš„AIæ¨¡å‹åŠ¨æ€ç®¡ç†å™¨
 * 
 * åŠŸèƒ½:
 * 1. åŠ¨æ€åŠ è½½å’Œç®¡ç†8ä¸ªAIæ¨¡å‹
 * 2. é…ç½®é©±åŠ¨çš„æ¨¡å‹åˆ‡æ¢
 * 3. è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
 * 4. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
 */

const { EventEmitter } = require('events');
const fs = require('fs').promises;
const path = require('path');

// AIæ¨¡å‹é…ç½®
const AI_MODELS = {
  // å¤–éƒ¨æ¨¡å‹ - ç›´è¿DeepSeek
  'deepseek-chat': {
    name: 'DeepSeek Chat',
    provider: 'deepseek',
    endpoint: 'https://api.deepseek.com/v1/chat/completions',
    type: 'external',
    capabilities: ['chat', 'reasoning'],
    maxTokens: 4096,
    priority: 1
  },
  'deepseek-coder': {
    name: 'DeepSeek Coder',
    provider: 'deepseek',
    endpoint: 'https://api.deepseek.com/v1/chat/completions',
    type: 'external',
    capabilities: ['coding', 'analysis'],
    maxTokens: 8192,
    priority: 1
  },

  // å†…éƒ¨æ¨¡å‹ - é€šè¿‡ä¼ éŸ³ä»£ç†
  'transsion-qwen-plus': {
    name: 'Transsion Qwen Plus',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/qwen-plus',
    type: 'internal',
    capabilities: ['chat', 'analysis', 'reasoning'],
    maxTokens: 8192,
    priority: 2
  },
  'transsion-qwen-turbo': {
    name: 'Transsion Qwen Turbo',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/qwen-turbo',
    type: 'internal',
    capabilities: ['chat', 'fast-response'],
    maxTokens: 4096,
    priority: 3
  },
  'transsion-qwen-max': {
    name: 'Transsion Qwen Max',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/qwen-max',
    type: 'internal',
    capabilities: ['chat', 'complex-reasoning'],
    maxTokens: 16384,
    priority: 1
  },
  'transsion-qwen-long': {
    name: 'Transsion Qwen Long',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/qwen-long',
    type: 'internal',
    capabilities: ['long-context', 'document-analysis'],
    maxTokens: 32768,
    priority: 2
  },
  'transsion-glm-4-plus': {
    name: 'Transsion GLM-4 Plus',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/glm-4-plus',
    type: 'internal',
    capabilities: ['chat', 'multimodal'],
    maxTokens: 8192,
    priority: 2
  },
  'transsion-glm-4-0520': {
    name: 'Transsion GLM-4 0520',
    provider: 'transsion',
    endpoint: 'http://internal-proxy/glm-4-0520',
    type: 'internal',
    capabilities: ['chat', 'latest-features'],
    maxTokens: 8192,
    priority: 3
  }
};

class AIModelManager extends EventEmitter {
  constructor() {
    super();
    this.models = new Map();
    this.activeModels = new Set();
    this.modelStats = new Map();
    this.config = {
      loadBalancing: true,
      failover: true,
      healthCheckInterval: 30000,
      maxRetries: 3
    };
    this.healthCheckTimer = null;
  }

  async initialize() {
    console.log('ğŸ¤– åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†å™¨...');
    
    // åŠ è½½æ¨¡å‹é…ç½®
    await this.loadModelConfigurations();
    
    // å¯åŠ¨å¥åº·æ£€æŸ¥
    this.startHealthCheck();
    
    // åŠ è½½é…ç½®æ–‡ä»¶
    await this.loadConfigFromFile();
    
    console.log(`âœ… AIæ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œå…±åŠ è½½${this.models.size}ä¸ªæ¨¡å‹`);
    this.emit('initialized');
  }

  async loadModelConfigurations() {
    for (const [modelId, config] of Object.entries(AI_MODELS)) {
      this.models.set(modelId, {
        ...config,
        id: modelId,
        status: 'unknown',
        lastCheck: null,
        responseTime: 0,
        errorCount: 0,
        requestCount: 0,
        successCount: 0
      });
      
      this.modelStats.set(modelId, {
        totalRequests: 0,
        successfulRequests: 0,
        failedRequests: 0,
        averageResponseTime: 0,
        lastUsed: null
      });
    }
  }

  async loadConfigFromFile() {
    try {
      const configPath = path.join(process.cwd(), 'config', 'ai-models.json');
      const configData = await fs.readFile(configPath, 'utf-8');
      const fileConfig = JSON.parse(configData);
      
      // åˆå¹¶é…ç½®
      Object.assign(this.config, fileConfig);
      console.log('ğŸ“„ ä»é…ç½®æ–‡ä»¶åŠ è½½AIæ¨¡å‹é…ç½®');
    } catch (error) {
      console.log('âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®');
      await this.saveConfigToFile();
    }
  }

  async saveConfigToFile() {
    try {
      const configDir = path.join(process.cwd(), 'config');
      await fs.mkdir(configDir, { recursive: true });
      
      const configPath = path.join(configDir, 'ai-models.json');
      const configData = {
        ...this.config,
        models: Object.fromEntries(this.models),
        lastUpdated: new Date().toISOString()
      };
      
      await fs.writeFile(configPath, JSON.stringify(configData, null, 2));
      console.log('ğŸ’¾ AIæ¨¡å‹é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶');
    } catch (error) {
      console.error('âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥:', error.message);
    }
  }

  async checkModelHealth(modelId) {
    const model = this.models.get(modelId);
    if (!model) return false;

    try {
      const startTime = Date.now();
      
      // è¿™é‡Œåº”è¯¥å®é™…è°ƒç”¨æ¨¡å‹APIè¿›è¡Œå¥åº·æ£€æŸ¥
      // ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªæ£€æŸ¥
      const isHealthy = await this.simulateHealthCheck(model);
      
      const responseTime = Date.now() - startTime;
      
      model.status = isHealthy ? 'healthy' : 'unhealthy';
      model.lastCheck = new Date().toISOString();
      model.responseTime = responseTime;
      
      if (isHealthy) {
        model.errorCount = 0;
        this.activeModels.add(modelId);
      } else {
        model.errorCount++;
        this.activeModels.delete(modelId);
      }
      
      return isHealthy;
    } catch (error) {
      model.status = 'error';
      model.errorCount++;
      this.activeModels.delete(modelId);
      return false;
    }
  }

  async simulateHealthCheck(model) {
    // æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥ - åœ¨å®é™…ç¯å¢ƒä¸­è¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„API
    const random = Math.random();
    
    // å¤–éƒ¨æ¨¡å‹æœ‰95%çš„å¯ç”¨æ€§
    if (model.type === 'external') {
      return random > 0.05;
    }
    
    // å†…éƒ¨æ¨¡å‹æœ‰90%çš„å¯ç”¨æ€§
    return random > 0.1;
  }

  startHealthCheck() {
    if (this.healthCheckTimer) {
      clearInterval(this.healthCheckTimer);
    }

    this.healthCheckTimer = setInterval(async () => {
      console.log('ğŸ” æ‰§è¡ŒAIæ¨¡å‹å¥åº·æ£€æŸ¥...');
      
      const healthPromises = Array.from(this.models.keys()).map(modelId => 
        this.checkModelHealth(modelId)
      );
      
      await Promise.all(healthPromises);
      
      const healthyCount = this.activeModels.size;
      const totalCount = this.models.size;
      
      console.log(`ğŸ“Š å¥åº·æ£€æŸ¥å®Œæˆ: ${healthyCount}/${totalCount} æ¨¡å‹å¯ç”¨`);
      
      this.emit('healthCheckComplete', {
        healthy: healthyCount,
        total: totalCount,
        activeModels: Array.from(this.activeModels)
      });
      
    }, this.config.healthCheckInterval);
  }

  selectBestModel(capability = 'chat', excludeModels = []) {
    const availableModels = Array.from(this.activeModels)
      .filter(modelId => !excludeModels.includes(modelId))
      .map(modelId => this.models.get(modelId))
      .filter(model => model.capabilities.includes(capability))
      .sort((a, b) => {
        // æŒ‰ä¼˜å…ˆçº§å’Œå“åº”æ—¶é—´æ’åº
        if (a.priority !== b.priority) {
          return a.priority - b.priority;
        }
        return a.responseTime - b.responseTime;
      });

    return availableModels[0] || null;
  }

  async processRequest(request, capability = 'chat') {
    const model = this.selectBestModel(capability);
    
    if (!model) {
      throw new Error('æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹');
    }

    try {
      const startTime = Date.now();
      
      // è¿™é‡Œåº”è¯¥å®é™…è°ƒç”¨æ¨¡å‹API
      const response = await this.simulateModelRequest(model, request);
      
      const responseTime = Date.now() - startTime;
      
      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      this.updateModelStats(model.id, true, responseTime);
      
      return {
        model: model.id,
        response,
        responseTime
      };
      
    } catch (error) {
      this.updateModelStats(model.id, false, 0);
      
      // æ•…éšœè½¬ç§»
      if (this.config.failover) {
        const fallbackModel = this.selectBestModel(capability, [model.id]);
        if (fallbackModel) {
          console.log(`ğŸ”„ æ•…éšœè½¬ç§»: ${model.id} -> ${fallbackModel.id}`);
          return this.processRequest(request, capability);
        }
      }
      
      throw error;
    }
  }

  async simulateModelRequest(model, request) {
    // æ¨¡æ‹ŸAPIè°ƒç”¨ - åœ¨å®é™…ç¯å¢ƒä¸­è¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„API
    await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 200));
    
    return {
      content: `è¿™æ˜¯æ¥è‡ª${model.name}çš„æ¨¡æ‹Ÿå“åº”: ${request.slice(0, 50)}...`,
      model: model.id,
      usage: {
        promptTokens: request.length,
        completionTokens: 100,
        totalTokens: request.length + 100
      }
    };
  }

  updateModelStats(modelId, success, responseTime) {
    const stats = this.modelStats.get(modelId);
    if (!stats) return;

    stats.totalRequests++;
    stats.lastUsed = new Date().toISOString();
    
    if (success) {
      stats.successfulRequests++;
      stats.averageResponseTime = (stats.averageResponseTime + responseTime) / 2;
    } else {
      stats.failedRequests++;
    }
  }

  getModelStatus() {
    const status = {
      totalModels: this.models.size,
      activeModels: this.activeModels.size,
      models: {},
      statistics: {}
    };

    for (const [modelId, model] of this.models) {
      status.models[modelId] = {
        name: model.name,
        status: model.status,
        type: model.type,
        capabilities: model.capabilities,
        responseTime: model.responseTime,
        errorCount: model.errorCount,
        lastCheck: model.lastCheck
      };
    }

    for (const [modelId, stats] of this.modelStats) {
      status.statistics[modelId] = { ...stats };
    }

    return status;
  }

  async shutdown() {
    console.log('ğŸ›‘ å…³é—­AIæ¨¡å‹ç®¡ç†å™¨...');
    
    if (this.healthCheckTimer) {
      clearInterval(this.healthCheckTimer);
    }
    
    await this.saveConfigToFile();
    
    console.log('âœ… AIæ¨¡å‹ç®¡ç†å™¨å·²å…³é—­');
    this.emit('shutdown');
  }
}

module.exports = AIModelManager;
