# QMSç³»ç»ŸAPIæ–‡æ¡£ v2.0

**æ›´æ–°æ—¥æœŸ**: 2025-01-31  
**APIç‰ˆæœ¬**: v2.0  
**æ”¯æŒæ¨¡å‹**: 8ä¸ªAIæ¨¡å‹  
**APIç«¯ç‚¹**: 33ä¸ª

## ğŸŒ åŸºç¡€ä¿¡æ¯

### æœåŠ¡åœ°å€
- **ç»Ÿä¸€å…¥å£**: http://localhost:8080/api/
- **AIèŠå¤©æœåŠ¡**: http://localhost:3004/
- **é…ç½®ä¸­å¿ƒæœåŠ¡**: http://localhost:3003/

### è®¤è¯æ–¹å¼
- **Tokenè®¤è¯**: Bearer Token
- **ä¼šè¯ç®¡ç†**: Session + JWT
- **æƒé™æ§åˆ¶**: åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ (RBAC)

## ğŸ¤– AIæ¨¡å‹ç®¡ç† API

### 1. è·å–æ¨¡å‹åˆ—è¡¨
```http
GET /api/models
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": [
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "Azure (OpenAI)",
      "capabilities": {
        "reasoning": false,
        "tools": true,
        "vision": true,
        "streaming": true
      },
      "status": "active"
    },
    {
      "id": "o3",
      "name": "O3",
      "provider": "Azure (OpenAI)",
      "capabilities": {
        "reasoning": true,
        "tools": true,
        "vision": false,
        "streaming": true
      },
      "status": "active"
    }
  ]
}
```

### 2. åˆ‡æ¢é»˜è®¤æ¨¡å‹
```http
POST /api/models/switch
Content-Type: application/json

{
  "modelId": "gpt-4o"
}
```

### 3. æ¨¡å‹å¥åº·æ£€æŸ¥
```http
GET /api/models/{modelId}/health
```

### 4. æ¨¡å‹æµ‹è¯•
```http
POST /api/models/test
Content-Type: application/json

{
  "modelId": "gpt-4o",
  "message": "æµ‹è¯•æ¶ˆæ¯"
}
```

### 5. æ‰¹é‡æ¨¡å‹æµ‹è¯•
```http
POST /api/models/batch-test
Content-Type: application/json

{
  "models": ["gpt-4o", "claude-3.7-sonnet"],
  "message": "æ‰¹é‡æµ‹è¯•æ¶ˆæ¯"
}
```

### 6. æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
```http
GET /api/models/usage-stats
```

## ğŸ’¬ AIèŠå¤© API

### 1. æ™®é€šèŠå¤©
```http
POST /api/chat/send
Content-Type: application/json

{
  "message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è´¨é‡ç®¡ç†çš„åŸºæœ¬æ¦‚å¿µ",
  "modelId": "gpt-4o",
  "conversationId": "conv_123456789",
  "context": {
    "temperature": 0.7,
    "maxTokens": 2000
  }
}
```

### 2. å›¾åƒè¯†åˆ«èŠå¤©
```http
POST /api/chat/vision
Content-Type: application/json

{
  "message": "è¯·åˆ†æè¿™å¼ è´¨é‡æ§åˆ¶å›¾è¡¨",
  "imageUrl": "https://example.com/chart.jpg",
  "modelId": "gpt-4o",
  "conversationId": "conv_123456789"
}
```

### 3. æµå¼å“åº”èŠå¤©
```http
POST /api/chat/stream
Content-Type: application/json

{
  "message": "è¯·è¯¦ç»†è§£é‡ŠISO 9001æ ‡å‡†",
  "modelId": "gpt-4o",
  "conversationId": "conv_123456789"
}
```

**å“åº”æ ¼å¼**: Server-Sent Events (SSE)
```
data: {"type": "start", "conversationId": "conv_123456789"}
data: {"type": "content", "content": "ISO 9001æ˜¯..."}
data: {"type": "end", "messageId": "msg_123456789"}
```

### 4. å·¥å…·è°ƒç”¨èŠå¤©
```http
POST /api/chat/tools
Content-Type: application/json

{
  "message": "å¸®æˆ‘è®¡ç®—è´¨é‡æˆæœ¬",
  "modelId": "gpt-4o",
  "conversationId": "conv_123456789",
  "tools": [
    {
      "name": "calculator",
      "description": "æ•°å­¦è®¡ç®—å·¥å…·"
    }
  ]
}
```

### 5. è·å–å¯¹è¯å†å²
```http
GET /api/chat/conversations?page=1&limit=20
```

### 6. åˆ é™¤å¯¹è¯
```http
DELETE /api/chat/conversations/{conversationId}
```

### 7. å¯¼å‡ºå¯¹è¯è®°å½•
```http
POST /api/chat/export
Content-Type: application/json

{
  "conversationIds": ["conv_123", "conv_456"],
  "format": "pdf",
  "includeMetadata": true
}
```

### 8. ä¸‹è½½å¯¼å‡ºæ–‡ä»¶
```http
GET /api/chat/download/{filename}
```

## ğŸ“Š ç›‘æ§ç»Ÿè®¡ API

### 1. æ€»ä½“ç»Ÿè®¡
```http
GET /api/ai-monitoring/statistics/overall
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "totalRequests": 15420,
    "totalUsers": 156,
    "totalConversations": 2340,
    "averageResponseTime": 1.2,
    "successRate": 98.5,
    "topModels": [
      {"name": "GPT-4o", "usage": 45.2},
      {"name": "Claude 3.7", "usage": 28.7}
    ]
  }
}
```

### 2. ç”¨æˆ·ç»Ÿè®¡
```http
GET /api/ai-monitoring/statistics/users?period=7d
```

### 3. æ¨¡å‹ç»Ÿè®¡
```http
GET /api/ai-monitoring/statistics/models?period=30d
```

### 4. ä»ªè¡¨æ¿æ•°æ®
```http
GET /api/ai-monitoring/dashboard
```

### 5. å®æ—¶ç›‘æ§æŒ‡æ ‡
```http
GET /api/ai-monitoring/realtime-metrics
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "activeUsers": 23,
    "currentRequests": 5,
    "systemLoad": 0.65,
    "memoryUsage": 0.78,
    "responseTime": 1.1,
    "errorRate": 0.02
  }
}
```

## ğŸ” ç”¨æˆ·è®¤è¯ API

### 1. ç”¨æˆ·ç™»å½•
```http
POST /api/auth/login
Content-Type: application/json

{
  "username": "admin",
  "password": "password123"
}
```

### 2. ç”¨æˆ·æ³¨å†Œ
```http
POST /api/auth/register
Content-Type: application/json

{
  "username": "newuser",
  "password": "password123",
  "email": "user@example.com",
  "role": "user"
}
```

### 3. åˆ·æ–°Token
```http
POST /api/auth/refresh
Authorization: Bearer {refresh_token}
```

### 4. ç”¨æˆ·ç™»å‡º
```http
POST /api/auth/logout
Authorization: Bearer {access_token}
```

### 5. è·å–ç”¨æˆ·ä¿¡æ¯
```http
GET /api/auth/profile
Authorization: Bearer {access_token}
```

## âš™ï¸ ç³»ç»Ÿé…ç½® API

### 1. è·å–ç³»ç»Ÿé…ç½®
```http
GET /api/config/system
```

### 2. æ›´æ–°ç³»ç»Ÿé…ç½®
```http
PUT /api/config/system
Content-Type: application/json

{
  "aiSettings": {
    "defaultModel": "gpt-4o",
    "maxTokens": 2000,
    "temperature": 0.7
  },
  "systemSettings": {
    "enableLogging": true,
    "logLevel": "info"
  }
}
```

### 3. è·å–AIæ¨¡å‹é…ç½®
```http
GET /api/config/ai-models
```

### 4. æ›´æ–°AIæ¨¡å‹é…ç½®
```http
PUT /api/config/ai-models/{modelId}
Content-Type: application/json

{
  "enabled": true,
  "apiKey": "sk-...",
  "baseUrl": "https://api.openai.com/v1",
  "maxTokens": 4000,
  "temperature": 0.7
}
```

## ğŸ¥ å¥åº·æ£€æŸ¥ API

### 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
```http
GET /api/health
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "healthy",
  "timestamp": "2025-01-31T10:30:00Z",
  "services": {
    "chatService": "healthy",
    "configService": "healthy",
    "database": "healthy",
    "aiModels": {
      "gpt-4o": "healthy",
      "claude-3.7": "healthy",
      "deepseek-r1": "degraded"
    }
  },
  "metrics": {
    "uptime": 86400,
    "memoryUsage": 0.75,
    "cpuUsage": 0.45
  }
}
```

### 2. æœåŠ¡çŠ¶æ€æ£€æŸ¥
```http
GET /api/health/services
```

### 3. æ•°æ®åº“è¿æ¥æ£€æŸ¥
```http
GET /api/health/database
```

## ğŸ“ é”™è¯¯ç è¯´æ˜

| é”™è¯¯ç  | è¯´æ˜ | è§£å†³æ–¹æ¡ˆ |
|--------|------|----------|
| 200 | è¯·æ±‚æˆåŠŸ | - |
| 400 | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼ |
| 401 | æœªæˆæƒè®¿é—® | æ£€æŸ¥Tokenæ˜¯å¦æœ‰æ•ˆ |
| 403 | æƒé™ä¸è¶³ | è”ç³»ç®¡ç†å‘˜åˆ†é…æƒé™ |
| 404 | èµ„æºä¸å­˜åœ¨ | æ£€æŸ¥è¯·æ±‚è·¯å¾„ |
| 429 | è¯·æ±‚é¢‘ç‡è¿‡é«˜ | é™ä½è¯·æ±‚é¢‘ç‡ |
| 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | è”ç³»æŠ€æœ¯æ”¯æŒ |
| 503 | æœåŠ¡ä¸å¯ç”¨ | ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ |

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### JavaScript/Axiosç¤ºä¾‹
```javascript
// å‘é€èŠå¤©è¯·æ±‚
const response = await axios.post('/api/chat/send', {
  message: 'è¯·ä»‹ç»è´¨é‡ç®¡ç†ä½“ç³»',
  modelId: 'gpt-4o',
  conversationId: 'conv_' + Date.now()
}, {
  headers: {
    'Authorization': 'Bearer ' + token,
    'Content-Type': 'application/json'
  }
})

console.log(response.data)
```

### Python/Requestsç¤ºä¾‹
```python
import requests

# è·å–æ¨¡å‹åˆ—è¡¨
response = requests.get('http://localhost:8080/api/models', 
                       headers={'Authorization': f'Bearer {token}'})
models = response.json()
print(models)
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

- **å¹³å‡å“åº”æ—¶é—´**: < 2ç§’
- **å¹¶å‘æ”¯æŒ**: 100+ ç”¨æˆ·
- **å¯ç”¨æ€§**: 99.9%
- **é”™è¯¯ç‡**: < 1%
- **ååé‡**: 1000+ è¯·æ±‚/åˆ†é’Ÿ

## ğŸ”„ ç‰ˆæœ¬æ›´æ–°è®°å½•

### v2.0 (2025-01-31)
- âœ… æ–°å¢2ä¸ªAIæ¨¡å‹ (DeepSeek Chat, DeepSeek Reasoner)
- âœ… å¢åŠ ç›‘æ§ç»Ÿè®¡API (5ä¸ªç«¯ç‚¹)
- âœ… ä¼˜åŒ–æµå¼å“åº”æ€§èƒ½
- âœ… å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

### v1.0 (2025-01-15)
- âœ… åŸºç¡€AIèŠå¤©åŠŸèƒ½
- âœ… 6ä¸ªAIæ¨¡å‹é›†æˆ
- âœ… ç”¨æˆ·è®¤è¯å’Œæƒé™ç®¡ç†
- âœ… åŸºç¡€ç›‘æ§åŠŸèƒ½

é€šè¿‡è¿™ä»½APIæ–‡æ¡£ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿäº†è§£å’Œä½¿ç”¨QMSç³»ç»Ÿçš„æ‰€æœ‰åŠŸèƒ½æ¥å£ã€‚
